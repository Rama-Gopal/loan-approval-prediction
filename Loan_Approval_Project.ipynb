{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3039a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "407737b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1fe2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "loan_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "359f36e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd382b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.Loan_Status.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dcfbe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = loan_data.Loan_Status\n",
    "X = loan_data.drop(['Loan_ID', 'Loan_Status'], axis = 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Take the low cardinality categorical data for easy one-hot encoding later\n",
    "categorical_cols = [col for col in X_train_full.columns if X_train_full[col].dtype == 'object' and X_train_full[col].nunique() < 13]\n",
    "\n",
    "numerical_cols = [col for col in X_train_full.columns if X_train_full[col].dtype in ('int64', 'float64')]\n",
    "\n",
    "total_cols = categorical_cols + numerical_cols\n",
    "\n",
    "X_train = X_train_full[total_cols].copy()\n",
    "X_valid = X_valid_full[total_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8530ef4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender               11\n",
       "Married               3\n",
       "Dependents           14\n",
       "Education             0\n",
       "Self_Employed        28\n",
       "Property_Area         0\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           20\n",
       "Loan_Amount_Term     11\n",
       "Credit_History       38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dealing with missing values\n",
    "\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc074fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "cat_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "num_cols = list(set(X_train.columns) - set(cat_cols))\n",
    "\n",
    "# print(cat_cols)\n",
    "# print(num_cols)\n",
    "\n",
    "# print(X_train[num_cols].isnull().sum())\n",
    "\n",
    "# Imputing values for numerical/quantitative columns\n",
    "numerical_imputer = SimpleImputer()\n",
    "num_X_train = pd.DataFrame(numerical_imputer.fit_transform(X_train[num_cols]))\n",
    "num_X_valid = pd.DataFrame(numerical_imputer.transform(X_valid[num_cols]))\n",
    "# Imputation removed column names; put them back\n",
    "num_X_train.columns = X_train[num_cols].columns\n",
    "num_X_valid.columns = X_valid[num_cols].columns\n",
    "\n",
    "# print(num_X_train)\n",
    "\n",
    "# print(num_X_train.isnull().sum())\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "num_X_train = pd.DataFrame(scaler.fit_transform(num_X_train), columns = num_X_train.columns, index = num_X_train.index)\n",
    "num_X_valid = pd.DataFrame(scaler.transform(num_X_valid), columns = num_X_valid.columns, index = num_X_valid.index)\n",
    "\n",
    "# print(num_X_train)\n",
    "\n",
    "# print(X_train[cat_cols].isnull().sum())\n",
    "# Imputing values for categorical columns\n",
    "categorical_imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "cat_X_train = pd.DataFrame(categorical_imputer.fit_transform(X_train[cat_cols]))\n",
    "cat_X_valid = pd.DataFrame(categorical_imputer.transform(X_valid[cat_cols]))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "cat_X_train.columns = X_train[cat_cols].columns\n",
    "cat_X_valid.columns = X_valid[cat_cols].columns\n",
    "\n",
    "# print(cat_X_train)\n",
    "# print(cat_X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "563fc5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 2nd step : One-Hot Encoding for categorical columns\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output = False)\n",
    "OH_train = OH_encoder.fit_transform(cat_X_train)\n",
    "OH_valid = OH_encoder.transform(cat_X_valid)\n",
    "train_feature_names = OH_encoder.get_feature_names_out(cat_X_train.columns)\n",
    "valid_feature_names = OH_encoder.get_feature_names_out(cat_X_valid.columns)\n",
    "OH_train = pd.DataFrame(OH_train, columns = train_feature_names)\n",
    "OH_valid = pd.DataFrame(OH_valid, columns = valid_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "391e7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine your numerical columns with categorical columns to get final training and validation sets\n",
    "\n",
    "final_X_train = pd.concat([num_X_train, OH_train], axis = 1)\n",
    "final_X_valid = pd.concat([num_X_valid, OH_valid], axis = 1)\n",
    "# print(final_X_train.head())\n",
    "# print(final_X_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d8e50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 20  23]\n",
      " [  7 104]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.74      0.47      0.57        43\n",
      "           Y       0.82      0.94      0.87       111\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.78      0.70      0.72       154\n",
      "weighted avg       0.80      0.81      0.79       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "my_model = RandomForestClassifier(n_estimators=400, random_state=1)\n",
    "my_model.fit(final_X_train, y_train)\n",
    "predictions = my_model.predict(final_X_valid)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_valid, predictions))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f60309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 20  23]\n",
      " [  6 105]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.77      0.47      0.58        43\n",
      "           Y       0.82      0.95      0.88       111\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.79      0.71      0.73       154\n",
      "weighted avg       0.81      0.81      0.80       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_model = RandomForestClassifier(n_estimators=400, random_state=1, class_weight='balanced')\n",
    "my_model.fit(final_X_train, y_train)\n",
    "predictions = my_model.predict(final_X_valid)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_valid, predictions))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0dfcbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[24 19]\n",
      " [13 98]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.65      0.56      0.60        43\n",
      "           Y       0.84      0.88      0.86       111\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.74      0.72      0.73       154\n",
      "weighted avg       0.78      0.79      0.79       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "my_model2 = LogisticRegression(solver='liblinear', random_state=1, class_weight='balanced')\n",
    "my_model2.fit(final_X_train, y_train)\n",
    "predictions = my_model2.predict(final_X_valid)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_valid, predictions))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29487327",
   "metadata": {},
   "source": [
    "Absolutely, you definitely can and should mention this project in your resume when applying for Data Analyst roles! It demonstrates several key skills and experiences that are highly relevant to such positions.\n",
    "\n",
    "Here's why and how you can frame it:\n",
    "\n",
    "Why This Project is Great for Your Resume:\n",
    "\n",
    "End-to-End Data Analysis Workflow: You've gone through a complete process:\n",
    "Data Loading and Exploration: Understanding the dataset.\n",
    "Data Preprocessing: Handling missing values, encoding categorical features, scaling numerical features.\n",
    "Feature Engineering (Potential): You've discussed creating new features.\n",
    "Model Building: Selecting and training classification models (Random Forest, Logistic Regression).\n",
    "Model Evaluation: Using appropriate metrics (confusion matrix, classification report, accuracy).\n",
    "Model Comparison: Analyzing and comparing the performance of different models.\n",
    "Problem Solving: Identifying issues like class imbalance and trying different techniques to address them.\n",
    "Relevant Skills Demonstrated:\n",
    "Python Programming: Using libraries like Pandas, NumPy, Scikit-learn.\n",
    "Data Wrangling and Cleaning: Handling missing data, data transformation.\n",
    "Feature Engineering: (If you implemented any).\n",
    "Machine Learning Fundamentals: Understanding classification, model selection, training, and evaluation.\n",
    "Model Interpretation: Analyzing evaluation metrics and drawing conclusions.\n",
    "Problem-Solving: Identifying and addressing challenges like class imbalance and feature scaling.\n",
    "Real-World Problem: Loan approval is a tangible and understandable business problem.\n",
    "Quantifiable Results: You have evaluation metrics (accuracy, precision, recall, F1-score) that you can mention.\n",
    "Continuous Learning: You've shown a willingness to explore different models and techniques to improve performance.\n",
    "How to Mention It in Your Resume:\n",
    "\n",
    "You can include this project in a \"Projects\" or \"Data Science Projects\" section of your resume. Here are a few ways you can phrase it:\n",
    "\n",
    "Option 1 (Focus on the entire workflow):\n",
    "\n",
    "**Loan Approval Prediction Project**\n",
    "* Utilized Python (Pandas, NumPy, Scikit-learn) to build and evaluate machine learning models for predicting loan approval status based on a dataset of applicant information.\n",
    "* Performed comprehensive data preprocessing, including handling missing values (using SimpleImputer), encoding categorical features (using OneHotEncoder), and scaling numerical features (using MinMaxScaler).\n",
    "* Developed and compared classification models, including Random Forest and Logistic Regression, to predict loan approval ('Y'/'N').\n",
    "* Evaluated model performance using metrics such as accuracy, precision, recall, F1-score, confusion matrix, and classification report.\n",
    "* Investigated and addressed class imbalance in the target variable using techniques like `class_weight='balanced'`.\n",
    "* (Optional: If you did) Explored feature engineering techniques to potentially improve model performance.\n",
    "Option 2 (Highlighting model comparison):\n",
    "\n",
    "**Comparative Analysis of Machine Learning Models for Loan Approval Prediction**\n",
    "* Developed and compared the performance of Random Forest and Logistic Regression classifiers for predicting loan approval outcomes.\n",
    "* Implemented a full data preprocessing pipeline, including imputation, encoding, and scaling of features using Python and Scikit-learn.\n",
    "* Analyzed and contrasted the evaluation metrics (precision, recall, F1-score) of both models, considering the implications for business decisions related to loan approvals.\n",
    "* Addressed data imbalance using `class_weight='balanced'` to improve model sensitivity to the minority class.\n",
    "Key Things to Emphasize:\n",
    "\n",
    "The tools and technologies you used (Python, Pandas, Scikit-learn).\n",
    "The steps you took in the data analysis process.\n",
    "The different models you experimented with.\n",
    "How you evaluated the models and the key findings (e.g., the trade-offs between precision and recall for different models).\n",
    "Any specific techniques you used to improve performance (e.g., handling class imbalance).\n",
    "(If you did) Any quantifiable results or improvements you achieved.\n",
    "During Interviews:\n",
    "\n",
    "Be prepared to discuss this project in detail. You should be able to explain:\n",
    "\n",
    "Your motivation for choosing this project.\n",
    "The challenges you faced (e.g., missing data, class imbalance).\n",
    "The steps you took to address those challenges.\n",
    "Your understanding of the different models you used and why you chose them.\n",
    "How you interpreted the evaluation metrics and what they mean in the context of loan approval.\n",
    "What you learned from the project and what you might do differently in the future.\n",
    "In conclusion, this is a valuable project that showcases many of the skills a Data Analyst needs. Definitely include it in your resume and be ready to talk about it during interviews! Good luck with your job applications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfcaba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
